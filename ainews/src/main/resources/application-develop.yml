server:
  port: 16001

spring:
  config:
    import:
      - file:.env.ainews[.properties]
  datasource:
    url: ${DEVELOP_DB_URL}
    username: ${DEVELOP_DB_USERNAME}
    password: ${DEVELOP_DB_PASSWORD}
    driver-class-name: com.mysql.cj.jdbc.Driver
  jpa:
    hibernate:
      ddl-auto: create
    show-sql: true
    open-in-view: false
    defer-datasource-initialization: true # hibernate가 초기화되기 전 data.sql 실행하는 것을 방지
    properties:
      hibernate:
        default_batch_fetch_size: 100
        format_sql: true
app:
  client:
    gemini:
      key: ${DEVELOP_GEMINI_KEY}
      host: ${DEVELOP_GEMINI_HOST}
      url: ${DEVELOP_GEMINI_URL}
      request-body-base: ${DEVELOP_REQUEST_BODY_BASE}

  kafka:

    producer:

      # 일반 메시지 전송용 Kafka Producer 설정
      normal:
        bootstrap-servers: ${DEVELOP_KAFKA_PRODUCER_NORMAL_SERVERS} # Kafka 브로커 주소 (복수 개일 경우 쉼표로 구분)
        acks: all                                # 메시지 전송 확인 수준 (0: 확인 안 함, 1: 리더만 확인, all: 모든 ISR 복제본 확인)
        retries: 3                               # 전송 실패 시 재시도 횟수
        retry-backoff-ms: 5000                   # 재시도 간 대기 시간 (ms)
        enable-idempotence: true                 # 멱등성 활성화 (중복 메시지 전송 방지, 순서 보장에 필수)
        max-in-flight-requests-per-connection: 5 # 커넥션당 병렬 전송 요청 수 (enable-idempotence=true 시 5 이하 권장)
        linger-ms: 20                            # 배치 전송을 위한 지연 시간 (ms) - 일정 시간 동안 데이터를 모아 전송
        batch-size: 16384                        # 배치 최대 크기 (byte) - 지정된 크기만큼 쌓이면 즉시 전송 (예: 16KB)
        compression-type: none                   # 메시지 압축 방식 (none, gzip, snappy, lz4, zstd 등)
        topic:
          news-info:
            topic-name: ${DEVELOP_KAFKA_PRODUCER_NORMAL_NEWS_INFO_TOPIC_NAME}
          tag-info:
            topic-name: ${DEVELOP_KAFKA_PRODUCER_NORMAL_TAG_INFO_TOPIC_NAME}

      # 예외 상황(DLQ 등) 전송용 Kafka Producer 설정
      exceptional:
        bootstrap-servers: ${DEVELOP_KAFKA_PRODUCER_EXCEPTION_SERVERS}
        acks: all
        retries: 5                               # 일반보다 재시도 횟수를 높게 설정하여 중요 메시지 보존 강화
        retry-backoff-ms: 5000
        enable-idempotence: true
        max-in-flight-requests-per-connection: 3
        linger-ms: 20
        batch-size: 16384                        # 배치 전송 크기를 크게 설정 (32KB)
        compression-type: none                 # 네트워크 효율 향상을 위한 압축 사용 (snappy는 속도와 압축률의 균형형)
        topic:
          originnews-info-dlq:
            topic-name: ${DEVELOP_KAFKA_PRODUCER_EXCEPTION_ORIGINNEWS_INFO_DLQ_TOPIC_NAME}
          ainews-dlq:
            topic-name: ${DEVELOP_KAFKA_PRODUCER_EXCEPTION_AINEWS_DLQ_TOPIC_NAME}
          news-info-dlq:
            topic-name: ${DEVELOP_KAFKA_PRODUCER_EXCEPTION_NEWS_INFO_DLQ_TOPIC_NAME}
          tag-info-dlq:
            topic-name: ${DEVELOP_KAFKA_PRODUCER_EXCEPTION_TAG_INFO_DLQ_TOPIC_NAME}

    consumer:

      # 일반 Consumer 설정
      normal:
        bootstrap-servers: ${DEVELOP_KAFKA_CONSUMER_NORMAL_SERVERS}  # Kafka 클러스터 주소
        enable-auto-commit: true                     # 오프셋 자동 커밋 여부 (false 시 수동 커밋 필요)
        enable-spring-ackmode-immediate: false       # 스프링측 수동 커밋 즉시 적용 : enable-auto-commit 이 false 인경우만 true 로 설정할것
        auto-offset-reset: latest                    # 초기 오프셋이 없을 경우 처리 기준 (latest: 가장 마지막, earliest: 처음부터)
        max-poll-records: 500                        # poll() 호출 시 한 번에 가져올 최대 레코드 수 (처리량 조절 용도)
        max-poll-interval-ms: 300000                 # poll() 간 최대 허용 시간 (ms), 초과 시 Consumer는 죽은 것으로 간주되어 rebalance 발생
        session-timeout-ms: 10000                    # Consumer가 heartbeat 를 보내지 않으면 죽은 것으로 간주되는 시간 (ms)
        concurrency: 1                               # 병렬 처리 Consumer 수 (KafkaListenerContainerFactory 등에서 사용)
        topic:
          originnews-info:
            topic-name: ${DEVELOP_KAFKA_CONSUMER_NORMAL_TOPIC_ORIGINNEWS_INFO_TOPIC_NAME}
            group-id: ${DEVELOP_KAFKA_CONSUMER_NORMAL_TOPIC_ORIGINNEWS_INFO_GROUP_ID}

      # 예외 Consumer 설정 (예: DLQ 처리 전용)
      exception:
        bootstrap-servers: ${DEVELOP_KAFKA_CONSUMER_EXCEPTION_SERVERS}
        enable-auto-commit: true
        enable-spring-ackmode-immediate: false       # 스프링측 수동 커밋 즉시 적용 : enable-auto-commit 이 false 인경우만 true 로 설정할것
        auto-offset-reset: latest
        max-poll-records: 500
        max-poll-interval-ms: 300000
        session-timeout-ms: 10000
        concurrency: 1
        topic:
          originnews-info-dlq:
            topic-name: ${DEVELOP_KAFKA_CONSUMER_EXCEPTION_TOPIC_ORIGINNEWS_INFO_DLQ_TOPIC_NAME}
            group-id: ${DEVELOP_KAFKA_CONSUMER_EXCEPTION_TOPIC_ORIGINNEWS_INFO_DLQ_GROUP_ID}
          ainews-dlq:
            topic-name: ${DEVELOP_KAFKA_CONSUMER_EXCEPTION_TOPIC_AINEWS_DLQ_TOPIC_NAME}
            group-id: ${DEVELOP_KAFKA_CONSUMER_EXCEPTION_TOPIC_AINEWS_DLQ_GROUP_ID}
          news-info-dlq:
            topic-name: ${DEVELOP_KAFKA_CONSUMER_EXCEPTION_TOPIC_NEWS_INFO_DLQ_TOPIC_NAME}
            group-id: ${DEVELOP_KAFKA_CONSUMER_EXCEPTION_TOPIC_NEWS_INFO_DLQ_GROUP_ID}
          tag-info-dlq:
            topic-name: ${DEVELOP_KAFKA_CONSUMER_EXCEPTION_TOPIC_TAG_INFO_DLQ_TOPIC_NAME}
            group-id: ${DEVELOP_KAFKA_CONSUMER_EXCEPTION_TOPIC_TAG_INFO_DLQ_GROUP_ID}
